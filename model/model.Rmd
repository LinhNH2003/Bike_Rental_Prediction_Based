---
title: "R Notebook"
output: html_notebook
---

# 6. Model

## 6.1 Model dự đoán số xe trong ngày.

### 6.1.1 Feature engineering.

```{r}
data_model1 <- data
# Số hóa các giá trị categorical bằng mutate và case_when
data_model1 <- data_model1 |>
  mutate(
    seasons = case_when(
      seasons == "Autumn" ~ 1,
      seasons == "Spring" ~ 2,
      seasons == "Summer" ~ 3,
      seasons == "Winter" ~ 4,
      TRUE ~ NA_real_
    ),
    holiday = case_when(
      holiday == "Holiday" ~ 1,
      holiday == "No Holiday" ~ 2,
      TRUE ~ NA_real_
    ),
    day_of_week = case_when(
      day_of_week == "Monday" ~ 1,
      day_of_week == "Tuesday" ~ 2,
      day_of_week == "Wednesday" ~ 3,
      day_of_week == "Thursday" ~ 4,
      day_of_week == "Friday" ~ 5,
      day_of_week == "Saturday" ~ 6,
      day_of_week == "Sunday" ~ 7,
      TRUE ~ NA_real_
    )
  )
data_model1 <- dummy_cols(data_model1, select_columns = c("hour", "seasons", "day_of_week"), 
                            remove_first_dummy = TRUE, 
                            remove_selected_columns = TRUE)
data_model1 <- data_model1 |> janitor::clean_names()
data_model1 <- data_model1 |> dplyr::select(-c(date, day, month))
data_model1 <- data_model1 %>% rename(
  bike_count = rented_bike_count,
  temp_c = temperature_c,
  humidity_pct = humidity_percent,
  wind_speed = wind_speed_m_s,
  visibility = visibility_10m,
  dew_point_temp_c = dew_point_temperature_c,
  solar_rad = solar_radiation_mj_m2,
  rainfall = rainfall_mm,
  snowfall = snowfall_cm,
  hol = holiday,
  yr = year,
  hr_1 = hour_1,
  hr_2 = hour_2,
  hr_3 = hour_3,
  hr_4 = hour_4,
  hr_5 = hour_5,
  hr_6 = hour_6,
  hr_7 = hour_7,
  hr_8 = hour_8,
  hr_9 = hour_9,
  hr_10 = hour_10,
  hr_11 = hour_11,
  hr_12 = hour_12,
  hr_13 = hour_13,
  hr_14 = hour_14,
  hr_15 = hour_15,
  hr_16 = hour_16,
  hr_17 = hour_17,
  hr_18 = hour_18,
  hr_19 = hour_19,
  hr_20 = hour_20,
  hr_21 = hour_21,
  hr_22 = hour_22,
  hr_23 = hour_23,
  spring = seasons_2,
  summer = seasons_3,
  autumn = seasons_4,
  Mon = day_of_week_2,
  Tue = day_of_week_3,
  Wed = day_of_week_4,
  Thu = day_of_week_5,
  Fri = day_of_week_6,
  Sat = day_of_week_7
)

```

### 6.1.2 Xây dựng mô hình cơ bản.

```{r}
model_1 <- lm(bike_count ~ ., data = data_model1)
summary(model_1)
```

```{r}
par(mfrow=c(2,2))
plot(model_1 , which=1:4)
```

Nhận thấy mô hình có nhiều biến không có ý nghĩa thông kê và

### 6.1.3 Select feature.

Sử dụng phương pháp hồi quy từng bước kết hợp với CV.

```{r}
# Tạo hàm predict cho regsubsets
predict.regsubsets <- function(object, newdata, id_model){
  form <- as.formula(object$call[[2]])
  x_mat <- model.matrix(form, newdata)
  coef_est <- coef(object, id = id_model)
  x_vars <- names(coef_est)
  x_mat <- x_mat[, x_vars, drop = FALSE]  # Đảm bảo rằng x_mat có các biến cần thiết
  res <- x_mat %*% coef_est
  return(as.numeric(res))
}

n_data_model1 <- nrow(data_model1)
k <- 5
set.seed(21)
folds <- sample(rep(1:k, length = n_data_model1))

# Đảm bảo rằng số lượng tối đa các biến dự đoán không vượt quá số biến thực tế
nvmax_actual <- min(37, ncol(data_model1) - 1)
cv_error_model1_rj <- matrix(0, nrow = k, ncol = nvmax_actual)

for(r in 1:k){
  data_model1_train_r <- data_model1[folds != r, ]
  data_model1_test_r <- data_model1[folds == r, ]
  
  out_subset_model1_folds <- regsubsets(x = bike_count ~ ., data = data_model1_train_r,
                                        method = "exhaustive", nvmax = nvmax_actual)
  
  for(j in 1:nvmax_actual){
    pred_rj <- predict.regsubsets(out_subset_model1_folds,
                                  newdata = data_model1_test_r, id_model = j)
    cv_error_model1_rj[r, j] <- sqrt(mean((data_model1_test_r$bike_count - pred_rj)^2))
  }
}

cv_error_model1 <- colMeans(cv_error_model1_rj)
ggplot(data = data.frame(x = c(1:36), y = cv_error_model1),
  mapping = aes(x = x, y = y)) +
  geom_point() +
  geom_line() +
  labs(x = "Number of predictors", y = "RMSE") +
  theme_bw()
```

Nhận thấy khi ta dùng càng nhiều thuộc tính thì RMSE càng giảm, điều này không có ý nghĩa gì cả cho việc chọn lựa thuộc tính, nên ta sẽ dùng hồi quy từng phần với tiêu chí BIC.

```{r}
data_model1 <- data_model1
regsubset <- regsubsets(x = bike_count ~ ., data = data_model1, nvmax = 42,
                                  method = "exhaustive")

reg_summary <- summary(regsubset)

# Tiêu chí Mallow's Cp
best_model_cp <- which.min(reg_summary$cp)

# Tiêu chí BIC
best_model_bic <- which.min(reg_summary$bic)

# Tiêu chí Adjusted R²
best_model_adjr2 <- which.max(reg_summary$adjr2)

# Hiển thị số lượng biến tốt nhất dựa trên các tiêu chí
cat("Số lượng biến tốt nhất dựa trên tiêu chí Mallow's Cp:", best_model_cp, "\n")
cat("Số lượng biến tốt nhất dựa trên tiêu chí BIC:", best_model_bic, "\n")

# Lấy các biến của mô hình tốt nhất dựa trên tiêu chí Mallow's Cp
best_features_cp <- names(coef(regsubset, best_model_cp))
cat("Các biến tốt nhất dựa trên tiêu chí Mallow's Cp:", best_features_cp, "\n")

# Lấy các biến của mô hình tốt nhất dựa trên tiêu chí BIC
best_features_bic <- names(coef(regsubset, best_model_bic))
cat("Các biến tốt nhất dựa trên tiêu chí BIC:", best_features_bic, "\n")

```

```{r}
library(glmnet)
x <- model.matrix(bike_count ~ ., data_model1)[,-1]
y <- data_model1$bike_count
out_cv_lasso <- cv.glmnet(x = x, y = y, alpha = 1, type.measure = "mse", nfolds = 10, family = "gaussian")
print(out_cv_lasso)

```

```{r}
lambda_grid <- 10^seq(from = 10, to = -2, length = 100)
beta_lambda_lasso <- out_cv_lasso$lambda.min
out_lasso_md <- glmnet(x = x, y = y, alpha = 1, lambda = lambda_grid, family = "gaussian")
predict(out_lasso_md, s = beta_lambda_lasso, type = "coefficients")
```

```{r}
# Hợp nhất các biến của cả 3 tiêu chí
best_features_intersection <- intersect(best_features_cp, best_features_bic)

# Hiển thị tổng hợp các biến từ 3 tiêu chí
cat("Tổng hợp các biến từ 2 tiêu chí:", best_features_intersection, "\n")
```

### 6.1.4 Building model

Xây dựng mô hình mới với các thuộc tình vừa tìm được.

```{r}
# Tạo công thức hồi quy tuyến tính
formula <- as.formula(paste("bike_count ~", paste(best_features_intersection[-1], collapse = " + ")))

# Xây dựng mô hình hồi quy tuyến tính
model_1 <- lm(formula, data = data_model1)
summary(model_1)
```

```{r}
par(mfrow=c(2,2))
plot(model_1_cleaned , which=1:4)
```

```{r}
# Thực hiện kiểm định Durbin-Watson
dwtest_result <- dwtest(model_1)

# Hiển thị kết quả
print(dwtest_result)
```

```{r}
# Lấy thặng dư từ mô hình
residuals_model <- residuals(model_1)

# Vẽ đồ thị ACF
acf(residuals_model, main = "Autocorrelation Function (ACF) of Residuals")

# Vẽ đồ thị PACF
pacf(residuals_model, main = "Partial Autocorrelation Function (PACF) of Residuals")
```

```{r}
data_model1$bike_count_lag1 <- lag(data_model1$bike_count, 1)
data_model1 <- na.omit(data_model1)  # Loại bỏ các hàng NA do biến trễ tạo ra

formula <- as.formula(paste("bike_count ~", paste(best_features_intersection[-1], collapse = " + ")))

# Tạo lại mô hình
model_1 <- lm(formula, data = data_model1)
summary(model_1)
```

```{r}
par(mfrow=c(2,2))
plot(model_1 , which=1:4)
```

```{r}
library(lmtest)

check_assumptions <- function(model, data) {
  results <- list()
  
  # Kiểm tra tính tuyến tính
  results$resettest <- resettest(model)
  
  # Kiểm tra phân phối chuẩn của thặng dư
  results$shapiro_test <- shapiro.test(residuals(model))
  results$ks_test <- ks.test(residuals(model), "pnorm", mean = mean(residuals(model)), sd = sd(residuals(model)))
  
  # Kiểm tra tính đồng nhất của thặng dư
  results$bptest <- bptest(model)
  
  # Kiểm tra điểm ảnh hưởng quá mức
  cooks_dist <- cooks.distance(model)
  results$influential_points <- which(cooks_dist > (8 / nrow(data)))
  
  return(results)
}

# Kiểm tra các giả định của model_1
assumptions_results <- check_assumptions(model_1, data_model1)
print(assumptions_results)

```

```{r}
library(lmtest)
library(nortest)
library(tseries)

check_assumptions <- function(model, data) {
  results <- list()
  
  # Kiểm tra tính tuyến tính
  results$resettest <- resettest(model)
  
  # Kiểm tra phân phối chuẩn của thặng dư
  results$ad_test <- ad.test(residuals(model))
  results$lillie_test <- lillie.test(residuals(model))
  results$jarque_bera_test <- jarque.bera.test(residuals(model))
  
  # Kiểm tra tính đồng nhất của thặng dư
  results$bptest <- bptest(model)
  
  # Kiểm tra điểm ảnh hưởng quá mức
  cooks_dist <- cooks.distance(model)
  results$influential_points <- which(cooks_dist > (4 / nrow(data)))
  
  return(results)
}

# Kiểm tra các giả định của model_1
assumptions_results <- check_assumptions(model_1_cleaned, data_model1)
print(assumptions_results)

```

```{r}
# Xác định các điểm ảnh hưởng quá mức (influential points)
influential_points <- which(cooks.distance(model_1) > (4 / nrow(data_model1)))

# Loại bỏ các điểm ảnh hưởng quá mức khỏi tập dữ liệu
data_model1 <- data_model1[-influential_points, ]

formula <- as.formula(paste("bike_count ~", paste(best_features_intersection[-1], collapse = " + ")))

# Huấn luyện lại mô hình với dữ liệu đã được làm sạch
model_1_cleaned <- lm(formula, data = data_model1)


```

```{r}
summary(model_1_cleaned)
```

Nhận thấy đồ thị thặng dư khá vẻ tốt hơn và các biến trong mô hình điều có ý nghĩa thống kê, nhưng vẫn chưa tốt nên ta sẽ thực hiện thêm việc mở rộng mô hình.

### 6.1.5 Mở rộng mô hình.

```{r}
multi.scatter <- function(data, target) {
  # Initialize an empty list to store plots
  plots <- list()

  # Loop through each numeric variable
  for (col in names(data)) {
    # Check if current variable is numeric and not the target variable
    if (is.numeric(data[[col]]) && col != target) {
      # Create scatter plot
      scatter_plot <- ggplot(data, aes_string(x = col, y = target)) +
        geom_point(size = 2, color = "blue") +
        ggtitle(paste(col, "vs.", target)) +
        theme_minimal()

      # Add the plot to the list
      plots[[col]] <- scatter_plot
    }
  }

  # Arrange plots in a grid
  grid.arrange(grobs = plots, ncol = 3)  # Adjust ncol as needed

  # Return the list of plots (optional)
  return(plots)
}

# Call the function with numeric columns and target variable
multi.scatter(data_model1, "bike_count")
```

```{r}
knots_temp_c <- quantile(data_model1$temp_c, probs = c(0.75))

model_1_expand <- lm(formula = bike_count ~ 
                       bs(temp_c, knots = knots_temp_c, degree = 2) + 
                       humidity_pct +
                       poly(dew_point_temp_c, 2)  + 
                       poly(rainfall, 2) + hol + yr + hr_1 + 
                       hr_2 + hr_3 + hr_4 + hr_5 + 
                       hr_6  + hr_8 + hr_10 + 
                       hr_11 + hr_12 + hr_13 + hr_14 + 
                       hr_17 + hr_18 + hr_19 + 
                       hr_20 + hr_21  + 
                       spring + summer + autumn + Fri + Sat, data = data_model1)
summary(model_1_expand)
```

```{r}
# Xác định các điểm ảnh hưởng quá mức (influential points)
influential_points <- which(cooks.distance(model_1_expand) > (4 / nrow(data_model1)))

# Loại bỏ các điểm ảnh hưởng quá mức khỏi tập dữ liệu
data_model1 <- data_model1[-influential_points, ]

```

```{r}
# Kiểm tra sự độ lập thặng dư của mô hình
par(mfrow = c(2, 2))  # Hiển thị 4 đồ thị cùng một lúc

# Residuals vs Fitted
plot(model_1_expand, which = 1, main = "Residuals vs Fitted")

# Normal Q-Q
plot(model_1_expand, which = 2, main = "Normal Q-Q")

# Scale-Location
plot(model_1_expand, which = 3, main = "Scale-Location")

# Residuals vs Leverage
plot(model_1_expand, which = 5, main = "Residuals vs Leverage")

par(mfrow = c(1, 1))  # Trở về chế độ hiển thị mặc định
```

```{r}
# Lấy thặng dư từ mô hình
residuals_model <- residuals(model_1_expand)

# Vẽ đồ thị ACF
acf(residuals_model, main = "Autocorrelation Function (ACF) of Residuals")

# Vẽ đồ thị PACF
pacf(residuals_model, main = "Partial Autocorrelation Function (PACF) of Residuals")
```

**Nhận xét:**

-   Theo đồ thị **Residuals vs Fitted Values:** Điều này có thể chỉ ra rằng mô hình hồi quy tuyến tính không phù hợp.

-   Theo đồ thị **Normal Q-Q Plot:** Thặng dư không có phân phối chuẩn, không ứng giả định normality của thặng dư.

Nhận thấy mô hình không được tốt cho lắm, việc tiếp cận mô hình cũng không hay, nên ta thực hiện một hướng tiếp cận khác của dữ liệu để kiểm tra.

## 6.2 Model dự đoán số xe theo ngày.

### 6.2.1 Feature engineering.

```{r}
data_model2 <- data |> dplyr::select(-c(hour, day, month))
data_model2 <- data_model2 |>
  mutate(
    seasons = case_when(
      seasons == "Autumn" ~ 1,
      seasons == "Spring" ~ 2,
      seasons == "Summer" ~ 3,
      seasons == "Winter" ~ 4,
      TRUE ~ NA_real_
    ),
    holiday = case_when(
      holiday == "Holiday" ~ 1,
      holiday == "No Holiday" ~ 2,
      TRUE ~ NA_real_
    ),
    day_of_week = case_when(
      day_of_week == "Monday" ~ 1,
      day_of_week == "Tuesday" ~ 2,
      day_of_week == "Wednesday" ~ 3,
      day_of_week == "Thursday" ~ 4,
      day_of_week == "Friday" ~ 5,
      day_of_week == "Saturday" ~ 6,
      day_of_week == "Sunday" ~ 7,
      TRUE ~ NA_real_
    )
  )
data_model2 <- data_model2 |>
  group_by(date) |>
  dplyr::summarise(sum_bike_count = sum(rented_bike_count),
            mean_humidity = mean(humidity_percent),
            mean_wind_speed = mean(wind_speed_m_s),
            mean_visibility = mean(visibility_10m),
            mean_tempature = mean(temperature_c),
            mean_dew_point_temp = mean(dew_point_temperature_c),
            mean_solar_radiation = mean(solar_radiation_mj_m2),
            mean_rainfall = mean(rainfall_mm),
            mean_snowfall = mean(snowfall_cm),
            seasons = mean(seasons),
            day_of_week = mean(day_of_week),
            holiday = mean(holiday)
            ) 

data_model2 <- dummy_cols(data_model2, select_columns = c("seasons", "day_of_week"), 
                            remove_first_dummy = TRUE, 
                            remove_selected_columns = TRUE)
data_model2 <- data_model2 %>% rename(
  bike_count = sum_bike_count,
  humidity = mean_humidity,
  wind_speed = mean_wind_speed,
  visibility = mean_visibility,
  temperature = mean_tempature,
  dew_point_temp = mean_dew_point_temp,
  solar_radiation = mean_solar_radiation,
  rainfall = mean_rainfall,
  snowfall = mean_snowfall,
  holiday = holiday,
  spring = seasons_2,
  summer = seasons_3,
  autumn = seasons_4,
  Mon = day_of_week_2,
  Tue = day_of_week_3,
  Wed = day_of_week_4,
  Thu = day_of_week_5,
  Fri = day_of_week_6,
  Sat = day_of_week_7
)

head(data_model2)
```

```{r}
library(ggplot2)
library(gridExtra)


numeric_columns <- sapply(data_model2, is.numeric)
numeric_data <- data_model2[, numeric_columns]

num_cols <- ceiling(sqrt(sum(numeric_columns)))
num_rows <- ceiling(sum(numeric_columns) / num_cols)



# Tạo danh sách các biểu đồ histogram
plots <- lapply(names(numeric_data), function(col) {
  ggplot(numeric_data, aes_string(x = col)) +
    geom_histogram(binwidth = 30, fill = "lightblue", color = "white") +
    ggtitle(col)
})

# Sắp xếp các biểu đồ theo dạng lưới
do.call(grid.arrange, c(plots, ncol = num_cols))

```

```{r}
correlation_matrix <- cor(numeric_data)

# Plot the correlation matrix
corrplot(correlation_matrix, method = "shade",tl.cex = 0.5)
```

```{r}
multi.scatter <- function(data, target) {
  # Initialize an empty list to store plots
  plots <- list()

  # Loop through each numeric variable
  for (col in names(data)) {
    # Check if current variable is numeric and not the target variable
    if (is.numeric(data[[col]]) && col != target) {
      # Create scatter plot
      scatter_plot <- ggplot(data, aes_string(x = col, y = target)) +
        geom_point(size = 2, color = "blue") +
        ggtitle(paste(col, "vs.", target)) +
        theme_minimal()

      # Add the plot to the list
      plots[[col]] <- scatter_plot
    }
  }

  # Arrange plots in a grid
  grid.arrange(grobs = plots, ncol = 3)  # Adjust ncol as needed

  # Return the list of plots (optional)
  return(plots)
}

# Call the function with numeric columns and target variable
multi.scatter(data_model2, "sum_bike_count")
```

### 6.2.2 Xây dựng mô hình cơ bản.

```{r}
data_model2 <- data_model2 |> dplyr::select(-date)
model_2 <- lm(bike_count ~ ., data = data_model2 )
summary(model_2)
```

```{r}
# Tạo dữ liệu mới để dự đoán
new_data <- data.frame(
  mean_humidity = c(50, 60),
  mean_wind_speed = c(3, 5),
  mean_visibility = c(10, 15),
  mean_tempature = c(20, 22),
  mean_dew_point_temp = c(10, 12),
  mean_solar_radiation = c(200, 250),
  mean_rainfall = c(0, 0.5),
  mean_snowfall = c(0, 0),
  seasons = c(1, 2),
  day_of_week = c(3, 4),
  holiday = c(0, 1)
)

# Thực hiện dự đoán và tính khoảng tin cậy
predictions <- predict(model_2, newdata = new_data, interval = "confidence", level=0.95)

# Hiển thị kết quả
print(predictions)
```

```{r}

```

```{r}
par(mfrow=c(2,2))
plot(model_3 , which=1:4)
```

```{r}
library(lmtest)

check_assumptions <- function(model, data) {
  results <- list()
  
  # Kiểm tra tính tuyến tính
  results$resettest <- resettest(model)
  
  # Kiểm tra phân phối chuẩn của thặng dư
  results$shapiro_test <- shapiro.test(residuals(model))
  results$ks_test <- ks.test(residuals(model), "pnorm", mean = mean(residuals(model)), sd = sd(residuals(model)))
  
  # Kiểm tra tính đồng nhất của thặng dư
  results$bptest <- bptest(model)
  
  # Kiểm tra điểm ảnh hưởng quá mức
  cooks_dist <- cooks.distance(model)
  results$influential_points <- which(cooks_dist > (4 / nrow(data)))
  
  return(results)
}

# Kiểm tra các giả định của model_1
assumptions_results <- check_assumptions(model_2, data_model2)
print(assumptions_results)

```

```{r}
# Thực hiện kiểm định Durbin-Watson
dwtest_result <- dwtest(model_2)

# Hiển thị kết quả
print(dwtest_result)

```

```{r}
# Lấy thặng dư từ mô hình
residuals_model <- residuals(model_2)

# Vẽ đồ thị ACF
acf(residuals_model, main = "Autocorrelation Function (ACF) of Residuals")

# Vẽ đồ thị PACF
pacf(residuals_model, main = "Partial Autocorrelation Function (PACF) of Residuals")

```

### 6.2.3 Select feature.

Sử dụng phương pháp hồi quy từng bước.

```{r}
# Tạo hàm predict cho regsubsets
predict.regsubsets <- function(object, newdata, id_model){
  form <- as.formula(object$call[[2]])
  x_mat <- model.matrix(form, newdata)
  coef_est <- coef(object, id = id_model)
  x_vars <- names(coef_est)
  x_mat <- x_mat[, x_vars, drop = FALSE]  # Đảm bảo rằng x_mat có các biến cần thiết
  res <- x_mat %*% coef_est
  return(as.numeric(res))
}

n_data_model2 <- nrow(data_model2)
k <- 5
set.seed(21)
folds <- sample(rep(1:k, length = n_data_model2))

# Đảm bảo rằng số lượng tối đa các biến dự đoán không vượt quá số biến thực tế
nvmax_actual <- min(13, ncol(data_model2) - 1)
cv_error_model2_rj <- matrix(0, nrow = k, ncol = nvmax_actual)

for(r in 1:k){
  data_model2_train_r <- data_model2[folds != r, ]
  data_model2_test_r <- data_model2[folds == r, ]
  
  out_subset_model2_folds <- regsubsets(x = bike_count ~ ., data = data_model2_train_r,
                                        method = "exhaustive", nvmax = nvmax_actual, really.big = TRUE)
  
  for(j in 1:nvmax_actual){
    pred_rj <- predict.regsubsets(out_subset_model2_folds,
                                  newdata = data_model2_test_r, id_model = j)
    cv_error_model2_rj[r, j] <- sqrt(mean((data_model2_test_r$bike_count - pred_rj)^2))
  }
}

cv_error_model2 <- colMeans(cv_error_model2_rj)
ggplot(data = data.frame(x = c(1:nvmax_actual), y = cv_error_model2),
  mapping = aes(x = x, y = y)) +
  geom_point() +
  geom_line() +
  labs(x = "Number of predictors", y = "RMSE") +
  theme_bw()
```

Việc sử dụng RMSE không thấy được số lượng thuộc tính hợp lý, nên ta sẽ chuyển sang phương pháp khác.

```{r}
data_model2 <- data_model2
regsubset <- regsubsets(x = bike_count ~ ., data = data_model2, nvmax = 18,
                                  method = "exhaustive")

reg_summary <- summary(regsubset)

# Tiêu chí Mallow's Cp
best_model_cp <- which.min(reg_summary$cp)

# Tiêu chí BIC
best_model_bic <- which.min(reg_summary$bic)

# Tiêu chí Adjusted R²
best_model_adjr2 <- which.max(reg_summary$adjr2)

# Hiển thị số lượng biến tốt nhất dựa trên các tiêu chí
cat("Số lượng biến tốt nhất dựa trên tiêu chí Mallow's Cp:", best_model_cp, "\n")
cat("Số lượng biến tốt nhất dựa trên tiêu chí BIC:", best_model_bic, "\n")

# Lấy các biến của mô hình tốt nhất dựa trên tiêu chí Mallow's Cp
best_features_cp <- names(coef(regsubset, best_model_cp))
cat("Các biến tốt nhất dựa trên tiêu chí Mallow's Cp:", best_features_cp, "\n")

# Lấy các biến của mô hình tốt nhất dựa trên tiêu chí BIC
best_features_bic <- names(coef(regsubset, best_model_bic))
cat("Các biến tốt nhất dựa trên tiêu chí BIC:", best_features_bic, "\n")


```

```{r}
library(glmnet)
x <- model.matrix(bike_count ~ ., data_model2)[,-1]
y <- data_model2$bike_count
out_cv_lasso <- cv.glmnet(x = x, y = y, alpha = 1, type.measure = "mse", nfolds = 10, family = "gaussian")
print(out_cv_lasso)

```

```{r}
lambda_grid <- 10^seq(from = 10, to = -2, length = 100)
beta_lambda_lasso <- out_cv_lasso$lambda.min
out_lasso_md <- glmnet(x = x, y = y, alpha = 1, lambda = lambda_grid, family = "gaussian")
predict(out_lasso_md, s = beta_lambda_lasso, type = "coefficients")
```

```{r}
best_features_intersection <- unique(best_features_cp, best_features_bic)

# Hiển thị tổng hợp các biến từ 3 tiêu chí
cat("Tổng hợp các biến từ 2 tiêu chí:", best_features_intersection, "\n")
```

### 6.2.4 Building model

```{r}
# Tạo công thức hồi quy tuyến tính
formula <- as.formula(paste("bike_count ~", paste(best_features_bic[-1], collapse = " + ")))

# Xây dựng mô hình hồi quy tuyến tính
model_2 <- lm(formula, data = data_model2)
summary(model_2)
```

```{r}
par(mfrow=c(2,2))
plot(model_2 , which=1:4)
```

```{r}
# Xác định các điểm ảnh hưởng quá mức (influential points)
influential_points <- which(cooks.distance(model_2) > (4 / nrow(data_model2)))

# Loại bỏ các điểm ảnh hưởng quá mức khỏi tập dữ liệu
data_model2 <- data_model2[-influential_points, ]

formula <- as.formula(paste("bike_count ~", paste(best_features_intersection[-1], collapse = " + ")))

# Huấn luyện lại mô hình với dữ liệu đã được làm sạch
model_2_cleaned <- lm(formula, data = data_model2)
# Kiểm tra sự độ lập thặng dư của mô hình

par(mfrow=c(2,2))
plot(model_2_cleaned , which=1:4)
```

```{r}
par(mfrow=c(2,2))
plot(model_2_cleaned , which=1:4)
```

### 6.2.5 Mở rộng mô hình.

```{r}
knots_solar_radiation <- quantile(data_model2$solar_radiation, probs = c(0.5))
knots_humidity <- quantile(data_model2$humidity, probs = c(0.25, 0.5))
knots_wind_speed <- quantile(data_model2$wind_speed, probs = c(0.25, 0.5))

model_2_expand <- lm(bike_count ~ wind_speed +
  + 
                       bs(solar_radiation, knots = knots_solar_radiation, degree = 2) +
                       poly(dew_point_temp, degree = 3) + 
                       rainfall + holiday + spring + summer + autumn + Fri + Sat
                       
                       , data = data_model2
    )
summary(model_2_expand)

```

```{r}
# Kiểm tra sự độ lập thặng dư của mô hình
par(mfrow = c(2, 2))  # Hiển thị 4 đồ thị cùng một lúc

# Residuals vs Fitted
plot(model_2_expand, which = 1, main = "Residuals vs Fitted")

# Normal Q-Q
plot(model_2_expand, which = 2, main = "Normal Q-Q")

# Scale-Location
plot(model_2_expand, which = 3, main = "Scale-Location")

# Residuals vs Leverage
plot(model_2_expand, which = 5, main = "Residuals vs Leverage")

par(mfrow = c(1, 1))  # Trở về chế độ hiển thị mặc định


```

```{r}
# Lấy thặng dư từ mô hình
residuals_model <- residuals(model_2_expand)

# Vẽ đồ thị ACF
acf(residuals_model, main = "Autocorrelation Function (ACF) of Residuals")

# Vẽ đồ thị PACF
pacf(residuals_model, main = "Partial Autocorrelation Function (PACF) of Residuals")
```

```{r}
# Thực hiện kiểm định Durbin-Watson
dwtest_result <- dwtest(model_2_expand)

# Hiển thị kết quả
print(dwtest_result)
```

```{r}
library(lmtest)

check_assumptions <- function(model, data) {
  results <- list()
  
  # Kiểm tra tính tuyến tính
  results$resettest <- resettest(model)
  
  # Kiểm tra phân phối chuẩn của thặng dư
  results$shapiro_test <- shapiro.test(residuals(model))
  results$ks_test <- ks.test(residuals(model), "pnorm", mean = mean(residuals(model)), sd = sd(residuals(model)))
  
  # Kiểm tra tính đồng nhất của thặng dư
  results$bptest <- bptest(model)
  
  # Kiểm tra điểm ảnh hưởng quá mức
  cooks_dist <- cooks.distance(model)
  results$influential_points <- which(cooks_dist > ( 8 / nrow(data)))
  
  return(results)
}

# Kiểm tra các giả định của model_1
assumptions_results <- check_assumptions(model_2_expand, data_model2)
print(assumptions_results)
```

```{r}
predictions <- predict(model_2_expand, newdata = data_model2, interval = "confidence", level = 0.95)

# Giá trị thực tế
actual_values <- data_model2$bike_count

# Tính sai số tuyệt đối giữa giá trị thực tế và giá trị dự đoán (fit)
absolute_errors <- abs(actual_values - predictions[, "fit"])

# Tính trung bình sai số tuyệt đối (MAE)
mae <- mean(absolute_errors)


# Sử dụng phương pháp bootstrap để tính khoảng tin cậy cho MAE
set.seed(123)  # Đặt seed để kết quả có thể tái lập
bootstrap_samples <- 1000  # Số lượng mẫu bootstrap
bootstrap_mae <- numeric(bootstrap_samples)

for (i in 1:bootstrap_samples) {
  sample_indices <- sample(seq_len(nrow(data_model2)), replace = TRUE)
  sample_actual_values <- actual_values[sample_indices]
  sample_predictions <- predictions[sample_indices, "fit"]
  sample_absolute_errors <- abs(sample_actual_values - sample_predictions)
  bootstrap_mae[i] <- mean(sample_absolute_errors)
}

# Tính khoảng tin cậy 95% cho MAE
ci <- quantile(bootstrap_mae, probs = c(0.025, 0.975))

# Hiển thị kết quả
print(paste("Mean Absolute Error (MAE):", mae))
print(paste("95% Confidence Interval for MAE:", ci[1], "-", ci[2]))
```

```{r}
new_data <- data.frame(
  wind_speed = -962.58,
  temperature = 332.51,
  solar_radiation = 13286.33,
  rainfall = -3686.15,
  holiday = 1, # 1: Có ngày nghỉ, 0: Không phải ngày nghỉ
  spring = 0, # 1: Mùa xuân, 0: Không phải mùa xuân
  summer = 0, # 1: Mùa hè, 0: Không phải mùa hè
  autumn = 1, # 1: Mùa thu, 0: Không phải mùa thu
  Fri = 0, # 1: Thứ sáu, 0: Không phải thứ sáu
  Sat = 0  # 1: Thứ bảy, 0: Không phải thứ bảy
)

# Dự đoán giá trị bike_count sử dụng mô hình đã huấn luyện
predictions <- predict(model_2_expand, newdata = new_data, interval = "confidence", level=0.95)

# In kết quả dự đoán
print(predictions)
```

**Nhận xét:**

-   Theo đồ thị **Residuals vs Fitted Values:** Điều này cho thấy rằng mối quan hệ tuyến tính là hợp lý và giả định homoscedasticity (phương sai đồng nhất) được đáp ứng.

-   Theo đồ thị **Normal Q-Q Plot:** Thặng dư có phân phối gần với phân phối chuẩn, đáp ứng giả định normality của thặng dư.

-   Theo đồ thị **Scale-Location Plot:** Dù có mở rộng mô hình nhưng đường nằm ngang không hoàn toàn, thế nên có thể sử dụng mô hình phi tiến có thể sẽ tốt hơn.

```{r}
# Kiểm tra đa cộng tuyến (VIF)
library(car)
vif(model_2_expand)

```

**Nhận xét:** `GVIF^(1/(2*Df))` của tất cả các biến đều dưới 2, cho thấy không có vấn đề đa cộng tuyến nghiêm trọng giữa các biến độc lập.
Điều này có nghĩa là các biến không bị phụ thuộc tuyến tính lẫn nhau một cách đáng kể và mô hình có độ ổn định cao.

```{r}
# Kiểm tra Normality
shapiro.test(residuals(model_2_expand))

```

**Nhận xét:** P-value \> 0.05 cho thấy thặng dư có phân phối gần với phân phối chuẩn.
Điều này đáp ứng giả định normality của thặng dư, cho phép sử dụng các kiểm định thống kê tiếp theo và tăng độ tin cậy của các ước lượng từ mô hình.

```{r}
summary(model_2_expand)$coefficients

```

**Nhận xét:**

-   **Hệ số ước lượng (Estimate)**:

    -   `mean_humidity`: Hệ số này âm (-166.9517) cho thấy rằng khi độ ẩm trung bình tăng, số lượng xe đạp thuê giảm.

    -   `mean_wind_speed`: Hệ số này âm (-971.2965) cho thấy rằng khi tốc độ gió tăng, số lượng xe đạp thuê giảm.

    -   `holiday`: Hệ số này dương (3536.9579) cho thấy rằng vào ngày nghỉ lễ, số lượng xe đạp thuê tăng

-   **Giá trị t và p-value**:

    -   Tất cả các biến trong mô hình đều có giá trị p-value nhỏ hơn 0.05, cho thấy rằng chúng có ý nghĩa thống kê trong mô hình.

-   **Phân tích các thành phần hàm cơ sở (bs) và đa thức (poly)**:

    -   `bs(mean_solar_radiation, knots = knots_mean_solar_radiation, degree = 2)`: Các hệ số này đều có ý nghĩa thống kê cao (p-value rất nhỏ), cho thấy rằng biến `mean_solar_radiation` có ảnh hưởng phi tuyến tính đáng kể đến số lượng xe đạp thuê.

    -   `poly(mean_dew_point_temp, degree = 3)`: Tương tự, các hệ số này cũng có ý nghĩa thống kê cao, cho thấy rằng `mean_dew_point_temp` có ảnh hưởng phi tuyến tính quan trọng.

    -   `poly(mean_rainfall, degree = 2)` và `poly(seasons, 2)`: Các hệ số này cũng có ý nghĩa thống kê, cho thấy rằng các biến này có ảnh hưởng phi tuyến tính đến số lượng xe đạp thuê.
